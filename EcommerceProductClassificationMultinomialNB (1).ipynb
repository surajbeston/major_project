{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "VvT9rQ9_IsOv",
        "outputId": "e47bfdcb-fc7f-464d-afcb-34f29ff70157"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-210f76c9-973d-4f84-8a6f-9b3b60093b63\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-210f76c9-973d-4f84-8a6f-9b3b60093b63\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving gyapu.csv to gyapu.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['gyapu.csv']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['gyapu.csv']))\n"
      ],
      "metadata": {
        "id": "C2gr8bQpJ-xl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = data[\"extras.category\"].value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "zwQPibQcL5ZY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = categories.to_frame()\n"
      ],
      "metadata": {
        "id": "hHfoKR1UL7gz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories.columns= [\"Count\"]\n"
      ],
      "metadata": {
        "id": "m_3vgmqkL-xe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = categories.query(\"Count > 3\")\n"
      ],
      "metadata": {
        "id": "BCSClzdIMAff"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_truncated = data.drop(columns=[\"datetime_extracted\", \"extras.breadcrumb\", \"extras.sellerName\", \"image\", \"price\", \"url\", \"_id\", \"ecommerce\"])\n",
        "data_truncated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lIT8tQsDMCuz",
        "outputId": "21078f27-e32f-4013-fbb8-ef61f2c638d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             description  \\\n",
              "0      [\"Boosts Immunity & Metabolism\",\"Anti-Ageing P...   \n",
              "1      [\"Improves Hearth Health\",\"Moisturizes dry/tri...   \n",
              "2      [\"TOP CLASS QUALITY - Our towels are made of r...   \n",
              "3      [\"TOP CLASS QUALITY - Our towels are made of r...   \n",
              "4      [\"【LINT-FREE, SCRATCH-FREE, SWIRL-FREE, 】Car W...   \n",
              "...                                                  ...   \n",
              "12052                                                 []   \n",
              "12053  [\"Daily Protection: Dettol Bathing soap bar pr...   \n",
              "12054                                                 []   \n",
              "12055  [\"India's No.1 Floor Cleaning Brand. Recommend...   \n",
              "12056  [\"India's No.1 Floor Cleaning Brand. Recommend...   \n",
              "\n",
              "                     extras.category  \\\n",
              "0               Dry & Packaged Food    \n",
              "1               Dry & Packaged Food    \n",
              "2      Hygiene & Cleaning Essentials   \n",
              "3      Hygiene & Cleaning Essentials   \n",
              "4      Hygiene & Cleaning Essentials   \n",
              "...                              ...   \n",
              "12052                            NaN   \n",
              "12053                            NaN   \n",
              "12054                            NaN   \n",
              "12055                            NaN   \n",
              "12056                            NaN   \n",
              "\n",
              "                                                    name  \n",
              "0      Desi Grub Raw White Honey | Unpasteurized Unfi...  \n",
              "1      Desi Grub Apricot Kernel Oil Extra Virgin - 10...  \n",
              "2      12 Pcs Kitchen Dish Towels Super Absorbent  Ki...  \n",
              "3      6 Pcs Kitchen Dish Towels Super Absorbent  Kit...  \n",
              "4      Multicolor Waterproof Free Size Microfiber Han...  \n",
              "...                                                  ...  \n",
              "12052           Air Wick Nagpur Narangi L&O Refill 250ml  \n",
              "12053                         Dettol Soap Original 125gm  \n",
              "12054                            Tokla Tea 50 Bags 100Gm  \n",
              "12055                                 LIzol Floral 500ml  \n",
              "12056                                 Lizol Sandal 500ml  \n",
              "\n",
              "[12057 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d2e6b3f-ad3d-4ea3-b825-32b29ef3186a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>extras.category</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\"Boosts Immunity &amp; Metabolism\",\"Anti-Ageing P...</td>\n",
              "      <td>Dry &amp; Packaged Food</td>\n",
              "      <td>Desi Grub Raw White Honey | Unpasteurized Unfi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[\"Improves Hearth Health\",\"Moisturizes dry/tri...</td>\n",
              "      <td>Dry &amp; Packaged Food</td>\n",
              "      <td>Desi Grub Apricot Kernel Oil Extra Virgin - 10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[\"TOP CLASS QUALITY - Our towels are made of r...</td>\n",
              "      <td>Hygiene &amp; Cleaning Essentials</td>\n",
              "      <td>12 Pcs Kitchen Dish Towels Super Absorbent  Ki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\"TOP CLASS QUALITY - Our towels are made of r...</td>\n",
              "      <td>Hygiene &amp; Cleaning Essentials</td>\n",
              "      <td>6 Pcs Kitchen Dish Towels Super Absorbent  Kit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[\"【LINT-FREE, SCRATCH-FREE, SWIRL-FREE, 】Car W...</td>\n",
              "      <td>Hygiene &amp; Cleaning Essentials</td>\n",
              "      <td>Multicolor Waterproof Free Size Microfiber Han...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12052</th>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Air Wick Nagpur Narangi L&amp;O Refill 250ml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12053</th>\n",
              "      <td>[\"Daily Protection: Dettol Bathing soap bar pr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dettol Soap Original 125gm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12054</th>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tokla Tea 50 Bags 100Gm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12055</th>\n",
              "      <td>[\"India's No.1 Floor Cleaning Brand. Recommend...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LIzol Floral 500ml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12056</th>\n",
              "      <td>[\"India's No.1 Floor Cleaning Brand. Recommend...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lizol Sandal 500ml</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12057 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d2e6b3f-ad3d-4ea3-b825-32b29ef3186a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d2e6b3f-ad3d-4ea3-b825-32b29ef3186a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d2e6b3f-ad3d-4ea3-b825-32b29ef3186a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category_names = list(categories.index)\n",
        "data_truncated = data_truncated.rename(columns = {\"extras.category\": \"category\"})\n",
        "filtered_data = data_truncated\n",
        "data_truncated = data_truncated.dropna()\n",
        "queryset = [f'category.str.startswith(\"{name}\")' for name in category_names]\n",
        "filtered_data = data_truncated.query(\" | \".join(queryset), engine=\"python\")\n",
        "\n",
        "filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"[\", \"\")\n",
        "filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"]\", \"\")\n",
        "filtered_data[\"description\"] = filtered_data[\"description\"].str.replace('\"', \"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FRLzzVcMGOb",
        "outputId": "476b6a47-fd76-4c00-822b-c83bff169642"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-53f1e60aa6b3>:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"[\", \"\")\n",
            "<ipython-input-8-53f1e60aa6b3>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"[\", \"\")\n",
            "<ipython-input-8-53f1e60aa6b3>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"]\", \"\")\n",
            "<ipython-input-8-53f1e60aa6b3>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[\"description\"] = filtered_data[\"description\"].str.replace(\"]\", \"\")\n",
            "<ipython-input-8-53f1e60aa6b3>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[\"description\"] = filtered_data[\"description\"].str.replace('\"', \"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(filtered_data, test_size=0.2, random_state=42, shuffle=True)\n"
      ],
      "metadata": {
        "id": "2vu71CRLRrOT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qzwZAk9YSFom",
        "outputId": "8d3edc7d-b356-42d1-df0b-2e1957df2539"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            description            category  \\\n",
              "2252  Akshar Parichaya is a nepali books that introd...          Children's   \n",
              "299   Colin Eco Clean 5ltr ,Ultra shine formula for ...  Hygiene Essentials   \n",
              "5819  Ok Play Square Table Wooden,Product Dimensions...      Baby Furniture   \n",
              "6157  Battery capacity: 1200mAh.,A soft-lighting lam...         Table Lamps   \n",
              "6563  Asana Pranayama Mudra Bandha By Swami Satyanan...               Books   \n",
              "...                                                 ...                 ...   \n",
              "5291  Language: Nepali,Binding: Paperback,Publisher:...            Business   \n",
              "5326  Hardy’s Nottage Hill Chardonnay White Wine ,Al...    Australian Wines   \n",
              "5493  Little Genius Tool Box,Product Dimensions : 27...        Toys & Games   \n",
              "869   Nutritious and healthy,Store in cool dry place...           Groceries   \n",
              "7437  DISPLAY: LED Indicators, MODES: Cooling / Heat...     air conditioner   \n",
              "\n",
              "                                                   name  \n",
              "2252          Combo Of Pre-School Nepali Kids Books Set  \n",
              "299                           Colin Eco Clean 5ltr 1jar  \n",
              "5819                        Ok Play Square Table Wooden  \n",
              "6157              Remax KwangChe Series LED Lamp RT-L01  \n",
              "6563  Asana Pranayama Mudra Bandha By Swami Satyanan...  \n",
              "...                                                 ...  \n",
              "5291                      How To Attract Money (Nepali)  \n",
              "5326    Hardys Nottage Hill Chardonnay White Wine 750ml  \n",
              "5493                             Little Genius Tool Box  \n",
              "869                   Lindt Swiss Milk Raisen Nut 100gm  \n",
              "7437       Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG  \n",
              "\n",
              "[5829 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-292f535e-0661-4515-8a8d-f0020dfc8df0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2252</th>\n",
              "      <td>Akshar Parichaya is a nepali books that introd...</td>\n",
              "      <td>Children's</td>\n",
              "      <td>Combo Of Pre-School Nepali Kids Books Set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>Colin Eco Clean 5ltr ,Ultra shine formula for ...</td>\n",
              "      <td>Hygiene Essentials</td>\n",
              "      <td>Colin Eco Clean 5ltr 1jar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819</th>\n",
              "      <td>Ok Play Square Table Wooden,Product Dimensions...</td>\n",
              "      <td>Baby Furniture</td>\n",
              "      <td>Ok Play Square Table Wooden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6157</th>\n",
              "      <td>Battery capacity: 1200mAh.,A soft-lighting lam...</td>\n",
              "      <td>Table Lamps</td>\n",
              "      <td>Remax KwangChe Series LED Lamp RT-L01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6563</th>\n",
              "      <td>Asana Pranayama Mudra Bandha By Swami Satyanan...</td>\n",
              "      <td>Books</td>\n",
              "      <td>Asana Pranayama Mudra Bandha By Swami Satyanan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5291</th>\n",
              "      <td>Language: Nepali,Binding: Paperback,Publisher:...</td>\n",
              "      <td>Business</td>\n",
              "      <td>How To Attract Money (Nepali)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5326</th>\n",
              "      <td>Hardy’s Nottage Hill Chardonnay White Wine ,Al...</td>\n",
              "      <td>Australian Wines</td>\n",
              "      <td>Hardys Nottage Hill Chardonnay White Wine 750ml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5493</th>\n",
              "      <td>Little Genius Tool Box,Product Dimensions : 27...</td>\n",
              "      <td>Toys &amp; Games</td>\n",
              "      <td>Little Genius Tool Box</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>Nutritious and healthy,Store in cool dry place...</td>\n",
              "      <td>Groceries</td>\n",
              "      <td>Lindt Swiss Milk Raisen Nut 100gm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7437</th>\n",
              "      <td>DISPLAY: LED Indicators, MODES: Cooling / Heat...</td>\n",
              "      <td>air conditioner</td>\n",
              "      <td>Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5829 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-292f535e-0661-4515-8a8d-f0020dfc8df0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-292f535e-0661-4515-8a8d-f0020dfc8df0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-292f535e-0661-4515-8a8d-f0020dfc8df0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])\n"
      ],
      "metadata": {
        "id": "SYDW1F2RMJcW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "encoder = preprocessing.OrdinalEncoder()"
      ],
      "metadata": {
        "id": "OTkiFTCINZqc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.fit(np.reshape(filtered_data.category.to_numpy(), (len(filtered_data.category), 1)))\n",
        "Y = encoder.transform(np.reshape(train_data.category.to_numpy(), (len(train_data.category), 1)))"
      ],
      "metadata": {
        "id": "seccarsdNin9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y.reshape(-1)"
      ],
      "metadata": {
        "id": "wfPmLpl5NyLu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(train_data.description.to_numpy(), Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "rsclafcmOxla",
        "outputId": "019068ba-39ca-49d8-e369-3d16ef28fee7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.inverse_transform([text_clf.predict([\"Premium wine\"])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYFuwneNPlvq",
        "outputId": "80b2d788-40b5-4263-b9f0-d7138445e9d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Wine']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = text_clf.predict(test_data.description)"
      ],
      "metadata": {
        "id": "WaiYBHrlSlpm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jWUGMUUS3en",
        "outputId": "5651e452-97ba-4b8e-c117-315ce4a58be8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([180.,  49., 180., ..., 180.,  31.,  45.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = encoder.transform(np.reshape(test_data.category.to_numpy(), (len(test_data.category), 1)))"
      ],
      "metadata": {
        "id": "7wcuMVxRS5mS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNL24AUoQdpZ",
        "outputId": "b74fa9a8-6bd2-40d7-97b0-5b60db46af8d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         4\n",
            "         1.0       1.00      0.60      0.75        15\n",
            "         3.0       0.00      0.00      0.00         6\n",
            "         5.0       0.00      0.00      0.00         6\n",
            "         6.0       0.00      0.00      0.00         9\n",
            "         7.0       0.00      0.00      0.00        13\n",
            "         8.0       0.00      0.00      0.00         5\n",
            "         9.0       0.00      0.00      0.00         5\n",
            "        10.0       0.00      0.00      0.00         7\n",
            "        11.0       0.00      0.00      0.00         3\n",
            "        12.0       0.00      0.00      0.00         7\n",
            "        13.0       0.00      0.00      0.00         3\n",
            "        15.0       0.00      0.00      0.00         2\n",
            "        19.0       0.00      0.00      0.00         2\n",
            "        21.0       0.00      0.00      0.00         3\n",
            "        22.0       1.00      0.33      0.50         9\n",
            "        23.0       0.00      0.00      0.00         6\n",
            "        24.0       0.00      0.00      0.00         1\n",
            "        25.0       0.00      0.00      0.00        11\n",
            "        26.0       1.00      1.00      1.00         3\n",
            "        27.0       1.00      0.40      0.57        10\n",
            "        28.0       0.00      0.00      0.00         5\n",
            "        29.0       0.00      0.00      0.00         4\n",
            "        30.0       1.00      1.00      1.00         7\n",
            "        31.0       0.41      0.57      0.48        63\n",
            "        32.0       1.00      0.38      0.55         8\n",
            "        33.0       0.86      0.50      0.63        12\n",
            "        34.0       0.00      0.00      0.00         3\n",
            "        35.0       1.00      0.17      0.29         6\n",
            "        36.0       0.00      0.00      0.00         6\n",
            "        37.0       0.00      0.00      0.00         2\n",
            "        38.0       0.00      0.00      0.00         8\n",
            "        39.0       0.96      0.67      0.79        39\n",
            "        40.0       0.00      0.00      0.00        13\n",
            "        42.0       0.43      0.95      0.60        41\n",
            "        43.0       0.00      0.00      0.00         2\n",
            "        44.0       0.00      0.00      0.00         5\n",
            "        45.0       0.70      0.72      0.71        43\n",
            "        46.0       0.00      0.00      0.00         1\n",
            "        48.0       0.00      0.00      0.00        14\n",
            "        49.0       0.90      0.47      0.62        19\n",
            "        51.0       0.00      0.00      0.00         3\n",
            "        52.0       0.00      0.00      0.00         3\n",
            "        55.0       0.00      0.00      0.00         2\n",
            "        56.0       0.78      0.61      0.68        41\n",
            "        58.0       0.00      0.00      0.00         2\n",
            "        59.0       0.83      0.37      0.51        27\n",
            "        60.0       0.00      0.00      0.00         1\n",
            "        61.0       1.00      0.33      0.50         9\n",
            "        62.0       0.00      0.00      0.00         3\n",
            "        63.0       0.00      0.00      0.00         2\n",
            "        64.0       0.00      0.00      0.00        17\n",
            "        65.0       1.00      0.21      0.35        19\n",
            "        66.0       0.00      0.00      0.00         1\n",
            "        67.0       0.00      0.00      0.00         3\n",
            "        68.0       0.00      0.00      0.00        21\n",
            "        69.0       0.00      0.00      0.00         2\n",
            "        70.0       0.00      0.00      0.00         9\n",
            "        71.0       0.00      0.00      0.00         8\n",
            "        72.0       1.00      0.09      0.17        11\n",
            "        73.0       0.00      0.00      0.00         4\n",
            "        74.0       0.92      0.80      0.86        41\n",
            "        75.0       0.00      0.00      0.00         3\n",
            "        76.0       0.00      0.00      0.00         3\n",
            "        77.0       0.00      0.00      0.00         3\n",
            "        78.0       0.00      0.00      0.00        10\n",
            "        79.0       0.00      0.00      0.00         3\n",
            "        80.0       0.00      0.00      0.00         2\n",
            "        81.0       0.00      0.00      0.00         8\n",
            "        82.0       0.00      0.00      0.00         3\n",
            "        83.0       0.00      0.00      0.00         8\n",
            "        84.0       0.35      0.95      0.51        41\n",
            "        86.0       1.00      0.20      0.33         5\n",
            "        87.0       0.00      0.00      0.00         2\n",
            "        88.0       0.00      0.00      0.00         4\n",
            "        89.0       0.00      0.00      0.00         3\n",
            "        90.0       1.00      0.45      0.62        11\n",
            "        92.0       0.00      0.00      0.00         1\n",
            "        93.0       0.00      0.00      0.00         9\n",
            "        94.0       0.00      0.00      0.00         1\n",
            "        95.0       0.00      0.00      0.00         6\n",
            "        96.0       0.00      0.00      0.00         3\n",
            "        98.0       0.00      0.00      0.00         2\n",
            "        99.0       0.00      0.00      0.00         5\n",
            "       100.0       0.00      0.00      0.00         2\n",
            "       102.0       0.00      0.00      0.00         3\n",
            "       103.0       0.00      0.00      0.00         1\n",
            "       104.0       1.00      0.07      0.12        15\n",
            "       105.0       0.00      0.00      0.00         4\n",
            "       106.0       1.00      0.14      0.25         7\n",
            "       107.0       0.00      0.00      0.00         2\n",
            "       108.0       0.00      0.00      0.00         2\n",
            "       109.0       1.00      0.25      0.40         4\n",
            "       110.0       0.00      0.00      0.00         5\n",
            "       111.0       0.00      0.00      0.00         8\n",
            "       112.0       0.00      0.00      0.00         4\n",
            "       113.0       1.00      0.22      0.36         9\n",
            "       115.0       0.00      0.00      0.00         3\n",
            "       117.0       0.00      0.00      0.00         9\n",
            "       118.0       0.00      0.00      0.00         1\n",
            "       119.0       0.00      0.00      0.00         1\n",
            "       120.0       1.00      0.21      0.35        14\n",
            "       121.0       0.00      0.00      0.00         8\n",
            "       122.0       0.00      0.00      0.00         1\n",
            "       123.0       0.00      0.00      0.00        11\n",
            "       124.0       1.00      0.38      0.55         8\n",
            "       125.0       0.00      0.00      0.00         2\n",
            "       126.0       0.00      0.00      0.00         8\n",
            "       127.0       0.00      0.00      0.00         2\n",
            "       128.0       0.00      0.00      0.00        19\n",
            "       129.0       0.00      0.00      0.00         1\n",
            "       130.0       0.00      0.00      0.00         8\n",
            "       131.0       0.00      0.00      0.00         3\n",
            "       132.0       0.00      0.00      0.00         4\n",
            "       133.0       0.00      0.00      0.00         1\n",
            "       134.0       0.00      0.00      0.00         2\n",
            "       135.0       0.00      0.00      0.00         3\n",
            "       136.0       0.00      0.00      0.00         4\n",
            "       137.0       0.00      0.00      0.00         3\n",
            "       138.0       1.00      0.11      0.20         9\n",
            "       139.0       0.00      0.00      0.00         4\n",
            "       140.0       0.00      0.00      0.00         5\n",
            "       141.0       0.00      0.00      0.00         1\n",
            "       142.0       0.00      0.00      0.00         1\n",
            "       144.0       0.00      0.00      0.00        14\n",
            "       145.0       1.00      0.54      0.70        13\n",
            "       146.0       0.00      0.00      0.00         4\n",
            "       148.0       0.00      0.00      0.00         3\n",
            "       149.0       0.00      0.00      0.00         3\n",
            "       150.0       0.00      0.00      0.00         1\n",
            "       151.0       0.00      0.00      0.00         2\n",
            "       152.0       0.65      0.96      0.77        25\n",
            "       153.0       0.00      0.00      0.00         3\n",
            "       154.0       0.00      0.00      0.00         7\n",
            "       155.0       0.00      0.00      0.00         2\n",
            "       156.0       0.00      0.00      0.00         1\n",
            "       157.0       0.00      0.00      0.00        12\n",
            "       158.0       0.73      0.95      0.83        40\n",
            "       160.0       0.00      0.00      0.00         1\n",
            "       161.0       0.00      0.00      0.00         5\n",
            "       162.0       0.00      0.00      0.00         8\n",
            "       163.0       0.00      0.00      0.00         2\n",
            "       164.0       0.00      0.00      0.00         9\n",
            "       165.0       0.00      0.00      0.00         1\n",
            "       166.0       0.00      0.00      0.00         1\n",
            "       167.0       0.00      0.00      0.00         8\n",
            "       169.0       0.00      0.00      0.00         1\n",
            "       170.0       1.00      0.33      0.50         6\n",
            "       171.0       0.00      0.00      0.00         1\n",
            "       172.0       0.00      0.00      0.00         1\n",
            "       173.0       0.00      0.00      0.00         1\n",
            "       174.0       0.00      0.00      0.00         2\n",
            "       175.0       1.00      0.11      0.20         9\n",
            "       177.0       0.00      0.00      0.00         2\n",
            "       178.0       0.00      0.00      0.00         2\n",
            "       180.0       0.11      1.00      0.20        73\n",
            "       181.0       0.00      0.00      0.00         7\n",
            "       182.0       1.00      0.25      0.40         4\n",
            "       183.0       0.38      0.79      0.52        38\n",
            "       184.0       0.00      0.00      0.00         2\n",
            "       185.0       1.00      0.20      0.33         5\n",
            "       186.0       0.00      0.00      0.00         2\n",
            "       187.0       0.00      0.00      0.00        13\n",
            "       188.0       0.00      0.00      0.00         5\n",
            "       189.0       0.00      0.00      0.00         1\n",
            "       190.0       0.00      0.00      0.00         3\n",
            "       191.0       0.00      0.00      0.00         2\n",
            "       192.0       0.00      0.00      0.00         1\n",
            "       193.0       0.64      0.91      0.75        35\n",
            "       194.0       0.47      0.47      0.47        19\n",
            "       196.0       0.00      0.00      0.00         1\n",
            "       197.0       0.00      0.00      0.00         9\n",
            "       198.0       0.95      0.65      0.77        31\n",
            "       199.0       1.00      0.17      0.29         6\n",
            "       203.0       1.00      0.31      0.47        13\n",
            "\n",
            "    accuracy                           0.38      1458\n",
            "   macro avg       0.21      0.12      0.13      1458\n",
            "weighted avg       0.42      0.38      0.33      1458\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(encoder.categories_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj5b5ab2RKkR",
        "outputId": "92f9fde0-4202-48a0-e48e-8d389e473a0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Bags & Luggage ',\n",
              " ' Footwear',\n",
              " 'Action Figures & Collectibles',\n",
              " 'Air Treatment',\n",
              " 'Anniversary',\n",
              " 'Arts & Craft for Kids',\n",
              " 'Audio',\n",
              " 'Australian Wines',\n",
              " 'Auto Accessories',\n",
              " 'Baby Clothing',\n",
              " 'Baby Furniture',\n",
              " 'Baby Gear',\n",
              " 'Baby Health & Hygiene',\n",
              " 'Baby Hygiene Material',\n",
              " 'Baby Oil',\n",
              " 'Baby Safety & Accessories',\n",
              " 'Baby Shampoo',\n",
              " 'Baby Shower',\n",
              " 'Baby Strollers',\n",
              " 'Baby Swing',\n",
              " 'Backpacks & Carriers',\n",
              " 'Bags & Shoes',\n",
              " 'Bags & luggage',\n",
              " 'Bathing & Gromming ',\n",
              " 'Bathroom Safety',\n",
              " 'Beauty & Health ',\n",
              " 'Bedding and Its Accessories',\n",
              " 'Beer',\n",
              " 'Beverages ',\n",
              " 'Biography',\n",
              " 'Birthday',\n",
              " 'Books',\n",
              " 'Bottle',\n",
              " 'Bottle Feeding',\n",
              " 'Brandy',\n",
              " 'Bulbs',\n",
              " 'Business',\n",
              " 'Cables',\n",
              " 'Champagne',\n",
              " \"Children's\",\n",
              " 'Chilean Wines',\n",
              " 'Clock',\n",
              " 'Clothing ',\n",
              " 'Clothing Sets',\n",
              " 'Consumer Electronics',\n",
              " 'Cooking Essentials ',\n",
              " 'Cooktops & Ranges',\n",
              " 'Coolpad ',\n",
              " 'Covid ',\n",
              " 'Covid-19 Safety Gears',\n",
              " 'Dairy Products ',\n",
              " 'Decoration Lights',\n",
              " 'Diaper Bags',\n",
              " 'Diapers & Potty',\n",
              " 'Disposable Diapers',\n",
              " 'Domestic Wine ',\n",
              " 'Dry & Packaged Food ',\n",
              " 'Electric Food Steamers',\n",
              " 'Electric Kettles & Thermo Pots',\n",
              " 'Electronic Accessories ',\n",
              " 'Extension Cord / Power Socket',\n",
              " 'Fans',\n",
              " 'Fashion ',\n",
              " 'Feeding',\n",
              " 'Fiction',\n",
              " 'Fitness & Sports',\n",
              " 'Food Preparation',\n",
              " 'Footwear ',\n",
              " 'Fragrance',\n",
              " 'Freezers',\n",
              " 'French Wines',\n",
              " 'Frozen Item',\n",
              " 'Fruits & Vegetables ',\n",
              " 'Fryers',\n",
              " 'Furnishing & Decor',\n",
              " 'Furniture',\n",
              " 'G-bar',\n",
              " 'Gadget ',\n",
              " 'Gas Stoves',\n",
              " 'Geyser',\n",
              " 'Gin',\n",
              " 'Grinder',\n",
              " 'Groceries',\n",
              " 'Hair Care ',\n",
              " 'Headphone & Headset ',\n",
              " 'Health',\n",
              " 'Heater',\n",
              " 'Heating & Cooling',\n",
              " 'History',\n",
              " 'Home & Kitchen',\n",
              " 'Home and Lifestyle',\n",
              " 'Hookah',\n",
              " 'Hookazz',\n",
              " 'Household Item',\n",
              " 'Humidifier',\n",
              " 'Hygiene & Cleaning Essentials',\n",
              " 'Hygiene Essentials',\n",
              " 'Induction',\n",
              " 'Induction Cooker',\n",
              " 'Irons',\n",
              " 'Italian Wine',\n",
              " 'Jackets & Coats',\n",
              " 'Jewellery & Accessories ',\n",
              " \"Kid's Hygiene\",\n",
              " 'Kids Clothing',\n",
              " 'Kitchen Appliances',\n",
              " 'Kitchenware & Dinning',\n",
              " 'Knives & Sharpners',\n",
              " 'LED Television ',\n",
              " 'Lightings',\n",
              " 'Lingerie, sleep & Lounge',\n",
              " 'Liqueurs',\n",
              " 'Live Sound & Stage Equipment',\n",
              " 'Make-up ',\n",
              " 'Maternity - Others',\n",
              " 'Maternity Care',\n",
              " 'Maternity Wear',\n",
              " 'Mattresses & Bedding',\n",
              " 'Memoir',\n",
              " \"Men's Accessories \",\n",
              " \"Men's Clothing \",\n",
              " \"Men's Fashion\",\n",
              " \"Men's Pants \",\n",
              " 'Mens Grooming ',\n",
              " 'Men’s accessories',\n",
              " 'Microwave',\n",
              " 'Mobile & Tablet Accessories',\n",
              " 'Nail Care',\n",
              " 'Non-Fiction',\n",
              " 'One Plus ',\n",
              " 'Organic Products',\n",
              " 'Other Accessories',\n",
              " 'Other Gaming Options',\n",
              " 'Others Parts & Tools',\n",
              " 'Outwear & Jackets',\n",
              " 'Ovens',\n",
              " 'Pacifiers',\n",
              " 'Pacifiers & Accessories',\n",
              " 'Pet Food ',\n",
              " 'Pet Supplies ',\n",
              " 'Phones & Telecommunication',\n",
              " 'Pillows & Stools',\n",
              " 'Poco ',\n",
              " 'Poetry',\n",
              " 'Portable Speakers',\n",
              " 'Pressure Cooker',\n",
              " 'Projector Accessories ',\n",
              " 'Projectors ',\n",
              " 'Purifier',\n",
              " 'Range Hoods',\n",
              " 'Real me ',\n",
              " 'Redmi',\n",
              " 'Refrigerator ',\n",
              " 'Religion, spirituality, and new age',\n",
              " 'Rice Cookers',\n",
              " 'Romance',\n",
              " 'Rum',\n",
              " 'Self help',\n",
              " 'Skin care',\n",
              " 'Sleepwear',\n",
              " 'Slip-Ons & Loafers ',\n",
              " 'Small Kitchen Appliances',\n",
              " 'Smart Speakers ',\n",
              " 'Smart Television',\n",
              " 'Smart Watches',\n",
              " 'SmartWatch Accessories',\n",
              " 'Spanish Wine',\n",
              " 'Stands & Holders',\n",
              " 'Sun Protection',\n",
              " 'Sunglasses & Opticals ',\n",
              " 'Sunglasses & opticals ',\n",
              " 'Sweets & Chocolates',\n",
              " 'Swings, Jumpers & Bouncers',\n",
              " 'Table Lamps',\n",
              " 'Teethers',\n",
              " 'Television ',\n",
              " 'Tequila',\n",
              " 'Tools & Brushes ',\n",
              " 'Toothbrushes & Toothpaste',\n",
              " 'Tops & Tees',\n",
              " 'Toys & Games',\n",
              " 'Toys, Kids & Babies',\n",
              " 'Two Wheelers',\n",
              " 'Utensils',\n",
              " 'Vaccum Cleaner',\n",
              " 'Vodka',\n",
              " 'Wall mounts & Protectors',\n",
              " 'Washing Machine',\n",
              " 'Watches & Accessories ',\n",
              " 'Water Dispenser',\n",
              " 'Water Heater',\n",
              " 'Water Purifier',\n",
              " 'Water bottle',\n",
              " 'Whiskey',\n",
              " 'Wine',\n",
              " 'Wine Cellars',\n",
              " 'Wipes & Holders',\n",
              " 'Wireless & Car Chargers ',\n",
              " 'Women Fashion',\n",
              " \"Women's Fashion\",\n",
              " \"Women's Fashion \",\n",
              " 'Xiaomi Mobile ',\n",
              " 'Young adult',\n",
              " 'air conditioner']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "filtered_data[\"combined\"] = filtered_data[\"name\"] + \" \" + filtered_data[\"description\"] \n",
        "\n",
        "train_data, test_data = train_test_split(filtered_data, test_size=0.2, random_state=42, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wYw39BuT5D5",
        "outputId": "b233af7f-2665-48c6-9cc4-fe58fa2b1a60"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-8eecedc976e8>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[\"combined\"] = filtered_data[\"name\"] + \" \" + filtered_data[\"description\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "raQMvok5XXcB",
        "outputId": "af217b0d-15e9-4a26-81eb-1b5c68c2efc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            description            category  \\\n",
              "2252  Akshar Parichaya is a nepali books that introd...          Children's   \n",
              "299   Colin Eco Clean 5ltr ,Ultra shine formula for ...  Hygiene Essentials   \n",
              "5819  Ok Play Square Table Wooden,Product Dimensions...      Baby Furniture   \n",
              "6157  Battery capacity: 1200mAh.,A soft-lighting lam...         Table Lamps   \n",
              "6563  Asana Pranayama Mudra Bandha By Swami Satyanan...               Books   \n",
              "...                                                 ...                 ...   \n",
              "5291  Language: Nepali,Binding: Paperback,Publisher:...            Business   \n",
              "5326  Hardy’s Nottage Hill Chardonnay White Wine ,Al...    Australian Wines   \n",
              "5493  Little Genius Tool Box,Product Dimensions : 27...        Toys & Games   \n",
              "869   Nutritious and healthy,Store in cool dry place...           Groceries   \n",
              "7437  DISPLAY: LED Indicators, MODES: Cooling / Heat...     air conditioner   \n",
              "\n",
              "                                                   name  \\\n",
              "2252          Combo Of Pre-School Nepali Kids Books Set   \n",
              "299                           Colin Eco Clean 5ltr 1jar   \n",
              "5819                        Ok Play Square Table Wooden   \n",
              "6157              Remax KwangChe Series LED Lamp RT-L01   \n",
              "6563  Asana Pranayama Mudra Bandha By Swami Satyanan...   \n",
              "...                                                 ...   \n",
              "5291                      How To Attract Money (Nepali)   \n",
              "5326    Hardys Nottage Hill Chardonnay White Wine 750ml   \n",
              "5493                             Little Genius Tool Box   \n",
              "869                   Lindt Swiss Milk Raisen Nut 100gm   \n",
              "7437       Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG   \n",
              "\n",
              "                                               combined  \n",
              "2252  Combo Of Pre-School Nepali Kids Books Set Aksh...  \n",
              "299   Colin Eco Clean 5ltr 1jar Colin Eco Clean 5ltr...  \n",
              "5819  Ok Play Square Table Wooden Ok Play Square Tab...  \n",
              "6157  Remax KwangChe Series LED Lamp RT-L01 Battery ...  \n",
              "6563  Asana Pranayama Mudra Bandha By Swami Satyanan...  \n",
              "...                                                 ...  \n",
              "5291  How To Attract Money (Nepali) Language: Nepali...  \n",
              "5326  Hardys Nottage Hill Chardonnay White Wine 750m...  \n",
              "5493  Little Genius Tool Box Little Genius Tool Box,...  \n",
              "869   Lindt Swiss Milk Raisen Nut 100gm Nutritious a...  \n",
              "7437  Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG D...  \n",
              "\n",
              "[5829 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75e48623-cf95-48c4-ae2d-cede8db18957\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "      <th>name</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2252</th>\n",
              "      <td>Akshar Parichaya is a nepali books that introd...</td>\n",
              "      <td>Children's</td>\n",
              "      <td>Combo Of Pre-School Nepali Kids Books Set</td>\n",
              "      <td>Combo Of Pre-School Nepali Kids Books Set Aksh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>Colin Eco Clean 5ltr ,Ultra shine formula for ...</td>\n",
              "      <td>Hygiene Essentials</td>\n",
              "      <td>Colin Eco Clean 5ltr 1jar</td>\n",
              "      <td>Colin Eco Clean 5ltr 1jar Colin Eco Clean 5ltr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819</th>\n",
              "      <td>Ok Play Square Table Wooden,Product Dimensions...</td>\n",
              "      <td>Baby Furniture</td>\n",
              "      <td>Ok Play Square Table Wooden</td>\n",
              "      <td>Ok Play Square Table Wooden Ok Play Square Tab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6157</th>\n",
              "      <td>Battery capacity: 1200mAh.,A soft-lighting lam...</td>\n",
              "      <td>Table Lamps</td>\n",
              "      <td>Remax KwangChe Series LED Lamp RT-L01</td>\n",
              "      <td>Remax KwangChe Series LED Lamp RT-L01 Battery ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6563</th>\n",
              "      <td>Asana Pranayama Mudra Bandha By Swami Satyanan...</td>\n",
              "      <td>Books</td>\n",
              "      <td>Asana Pranayama Mudra Bandha By Swami Satyanan...</td>\n",
              "      <td>Asana Pranayama Mudra Bandha By Swami Satyanan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5291</th>\n",
              "      <td>Language: Nepali,Binding: Paperback,Publisher:...</td>\n",
              "      <td>Business</td>\n",
              "      <td>How To Attract Money (Nepali)</td>\n",
              "      <td>How To Attract Money (Nepali) Language: Nepali...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5326</th>\n",
              "      <td>Hardy’s Nottage Hill Chardonnay White Wine ,Al...</td>\n",
              "      <td>Australian Wines</td>\n",
              "      <td>Hardys Nottage Hill Chardonnay White Wine 750ml</td>\n",
              "      <td>Hardys Nottage Hill Chardonnay White Wine 750m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5493</th>\n",
              "      <td>Little Genius Tool Box,Product Dimensions : 27...</td>\n",
              "      <td>Toys &amp; Games</td>\n",
              "      <td>Little Genius Tool Box</td>\n",
              "      <td>Little Genius Tool Box Little Genius Tool Box,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>Nutritious and healthy,Store in cool dry place...</td>\n",
              "      <td>Groceries</td>\n",
              "      <td>Lindt Swiss Milk Raisen Nut 100gm</td>\n",
              "      <td>Lindt Swiss Milk Raisen Nut 100gm Nutritious a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7437</th>\n",
              "      <td>DISPLAY: LED Indicators, MODES: Cooling / Heat...</td>\n",
              "      <td>air conditioner</td>\n",
              "      <td>Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG</td>\n",
              "      <td>Tesla NIKOLACOOL PORTABLE AC TE-PT-12KHC-BLG D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5829 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75e48623-cf95-48c4-ae2d-cede8db18957')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75e48623-cf95-48c4-ae2d-cede8db18957 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75e48623-cf95-48c4-ae2d-cede8db18957');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.fit(np.reshape(filtered_data.category.to_numpy(), (len(filtered_data.category), 1)))\n",
        "Y = encoder.transform(np.reshape(train_data.category.to_numpy(), (len(train_data.category), 1)))"
      ],
      "metadata": {
        "id": "iFO50Y8BXZny"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y.reshape(-1)"
      ],
      "metadata": {
        "id": "0nWkViLpXtM3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(train_data.combined.to_numpy(), Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "5ln64PJhXxjS",
        "outputId": "17f43cc4-9722-48ad-cbc1-7c90846f82b6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = text_clf.predict(test_data.combined)"
      ],
      "metadata": {
        "id": "wPcvzLIFX1R6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = encoder.transform(np.reshape(test_data.category.to_numpy(), (len(test_data.category), 1)))"
      ],
      "metadata": {
        "id": "r9Rw1l_BYABv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted, zero_division = True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXJsdGW-YJb7",
        "outputId": "a8477372-4f5d-420a-cf1b-e6415a163b75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       1.00      0.80      0.89        15\n",
            "         3.0       1.00      0.17      0.29         6\n",
            "         5.0       1.00      0.00      0.00         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.86      0.46      0.60        13\n",
            "         8.0       1.00      0.00      0.00         5\n",
            "         9.0       1.00      0.00      0.00         5\n",
            "        10.0       1.00      0.00      0.00         7\n",
            "        11.0       1.00      0.00      0.00         3\n",
            "        12.0       1.00      0.00      0.00         7\n",
            "        13.0       1.00      0.00      0.00         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       1.00      0.00      0.00         3\n",
            "        22.0       1.00      0.44      0.62         9\n",
            "        23.0       1.00      0.00      0.00         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.00      0.00        11\n",
            "        26.0       1.00      1.00      1.00         3\n",
            "        27.0       1.00      0.70      0.82        10\n",
            "        28.0       1.00      0.00      0.00         5\n",
            "        29.0       1.00      0.00      0.00         4\n",
            "        30.0       1.00      1.00      1.00         7\n",
            "        31.0       0.48      0.86      0.61        63\n",
            "        32.0       1.00      0.50      0.67         8\n",
            "        33.0       0.60      0.75      0.67        12\n",
            "        34.0       1.00      0.00      0.00         3\n",
            "        35.0       1.00      0.00      0.00         6\n",
            "        36.0       1.00      0.00      0.00         6\n",
            "        37.0       1.00      0.00      0.00         2\n",
            "        38.0       1.00      0.00      0.00         8\n",
            "        39.0       0.97      0.82      0.89        39\n",
            "        40.0       1.00      0.15      0.27        13\n",
            "        42.0       0.43      1.00      0.60        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.00      0.00         5\n",
            "        45.0       0.64      0.74      0.69        43\n",
            "        46.0       1.00      0.00      0.00         1\n",
            "        48.0       1.00      0.00      0.00        14\n",
            "        49.0       0.83      0.53      0.65        19\n",
            "        51.0       1.00      0.00      0.00         3\n",
            "        52.0       1.00      0.00      0.00         3\n",
            "        55.0       1.00      0.00      0.00         2\n",
            "        56.0       0.82      0.78      0.80        41\n",
            "        58.0       1.00      0.00      0.00         2\n",
            "        59.0       0.87      0.48      0.62        27\n",
            "        60.0       1.00      0.00      0.00         1\n",
            "        61.0       1.00      0.33      0.50         9\n",
            "        62.0       1.00      0.00      0.00         3\n",
            "        63.0       1.00      0.00      0.00         2\n",
            "        64.0       1.00      0.00      0.00        17\n",
            "        65.0       1.00      0.37      0.54        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.00      0.00         3\n",
            "        68.0       1.00      0.00      0.00        21\n",
            "        69.0       1.00      0.00      0.00         2\n",
            "        70.0       1.00      0.33      0.50         9\n",
            "        71.0       1.00      0.00      0.00         8\n",
            "        72.0       1.00      0.09      0.17        11\n",
            "        73.0       1.00      0.00      0.00         4\n",
            "        74.0       0.88      0.93      0.90        41\n",
            "        75.0       1.00      0.00      0.00         3\n",
            "        76.0       1.00      0.00      0.00         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       1.00      0.00      0.00        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      0.00      0.00         2\n",
            "        81.0       1.00      0.25      0.40         8\n",
            "        82.0       1.00      0.00      0.00         3\n",
            "        83.0       0.00      0.00      0.00         8\n",
            "        84.0       0.34      1.00      0.51        41\n",
            "        86.0       1.00      0.40      0.57         5\n",
            "        87.0       1.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       1.00      0.00      0.00         3\n",
            "        90.0       1.00      0.55      0.71        11\n",
            "        92.0       1.00      0.00      0.00         1\n",
            "        93.0       1.00      0.00      0.00         9\n",
            "        94.0       1.00      0.00      0.00         1\n",
            "        95.0       1.00      0.00      0.00         6\n",
            "        96.0       1.00      0.00      0.00         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      0.00      0.00         5\n",
            "       100.0       1.00      0.00      0.00         2\n",
            "       102.0       1.00      0.00      0.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       1.00      0.20      0.33        15\n",
            "       105.0       1.00      0.00      0.00         4\n",
            "       106.0       1.00      0.00      0.00         7\n",
            "       107.0       1.00      0.00      0.00         2\n",
            "       108.0       1.00      0.00      0.00         2\n",
            "       109.0       1.00      0.50      0.67         4\n",
            "       110.0       1.00      0.00      0.00         5\n",
            "       111.0       1.00      0.00      0.00         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.67      0.44      0.53         9\n",
            "       115.0       1.00      0.00      0.00         3\n",
            "       117.0       1.00      0.00      0.00         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      0.00      0.00         1\n",
            "       120.0       0.75      0.21      0.33        14\n",
            "       121.0       1.00      0.00      0.00         8\n",
            "       122.0       1.00      0.00      0.00         1\n",
            "       123.0       1.00      0.00      0.00        11\n",
            "       124.0       1.00      0.38      0.55         8\n",
            "       125.0       1.00      0.00      0.00         2\n",
            "       126.0       1.00      0.00      0.00         8\n",
            "       127.0       1.00      0.00      0.00         2\n",
            "       128.0       1.00      0.00      0.00        19\n",
            "       129.0       1.00      0.00      0.00         1\n",
            "       130.0       1.00      0.12      0.22         8\n",
            "       131.0       1.00      0.00      0.00         3\n",
            "       132.0       1.00      0.00      0.00         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.00      0.00         3\n",
            "       136.0       1.00      0.00      0.00         4\n",
            "       137.0       1.00      0.00      0.00         3\n",
            "       138.0       1.00      0.11      0.20         9\n",
            "       139.0       1.00      0.00      0.00         4\n",
            "       140.0       1.00      0.00      0.00         5\n",
            "       141.0       1.00      0.00      0.00         1\n",
            "       142.0       1.00      0.00      0.00         1\n",
            "       144.0       1.00      0.07      0.13        14\n",
            "       145.0       1.00      0.62      0.76        13\n",
            "       146.0       1.00      0.00      0.00         4\n",
            "       148.0       1.00      0.00      0.00         3\n",
            "       149.0       1.00      0.00      0.00         3\n",
            "       150.0       1.00      0.00      0.00         1\n",
            "       151.0       1.00      0.00      0.00         2\n",
            "       152.0       0.80      0.96      0.87        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       1.00      0.57      0.73         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       1.00      0.00      0.00        12\n",
            "       158.0       0.65      1.00      0.78        40\n",
            "       160.0       1.00      0.00      0.00         1\n",
            "       161.0       1.00      0.00      0.00         5\n",
            "       162.0       1.00      0.00      0.00         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       0.00      0.00      0.00         9\n",
            "       165.0       1.00      0.00      0.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       1.00      0.00      0.00         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       1.00      0.33      0.50         6\n",
            "       171.0       1.00      0.00      0.00         1\n",
            "       172.0       1.00      0.00      0.00         1\n",
            "       173.0       1.00      0.00      0.00         1\n",
            "       174.0       1.00      0.00      0.00         2\n",
            "       175.0       1.00      0.11      0.20         9\n",
            "       177.0       1.00      0.00      0.00         2\n",
            "       178.0       1.00      0.00      0.00         2\n",
            "       180.0       0.14      1.00      0.25        73\n",
            "       181.0       1.00      0.00      0.00         7\n",
            "       182.0       1.00      0.25      0.40         4\n",
            "       183.0       0.34      0.82      0.48        38\n",
            "       184.0       1.00      0.00      0.00         2\n",
            "       185.0       1.00      0.20      0.33         5\n",
            "       186.0       1.00      0.00      0.00         2\n",
            "       187.0       1.00      0.00      0.00        13\n",
            "       188.0       1.00      0.00      0.00         5\n",
            "       189.0       1.00      0.00      0.00         1\n",
            "       190.0       1.00      0.00      0.00         3\n",
            "       191.0       1.00      0.00      0.00         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.72      0.97      0.83        35\n",
            "       194.0       0.46      0.68      0.55        19\n",
            "       196.0       1.00      0.00      0.00         1\n",
            "       197.0       1.00      0.11      0.20         9\n",
            "       198.0       0.95      0.68      0.79        31\n",
            "       199.0       1.00      0.17      0.29         6\n",
            "       203.0       1.00      0.77      0.87        13\n",
            "\n",
            "    accuracy                           0.45      1458\n",
            "   macro avg       0.95      0.15      0.16      1458\n",
            "weighted avg       0.81      0.45      0.39      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_names = text_clf.predict(test_data.name)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted_names, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WicWNhXpYNZP",
        "outputId": "eeaa4318-1381-4e81-ed92-a6da16a6fd56"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       1.00      0.73      0.85        15\n",
            "         3.0       1.00      0.50      0.67         6\n",
            "         5.0       1.00      0.00      0.00         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.90      0.69      0.78        13\n",
            "         8.0       1.00      0.00      0.00         5\n",
            "         9.0       1.00      0.00      0.00         5\n",
            "        10.0       1.00      0.00      0.00         7\n",
            "        11.0       1.00      0.00      0.00         3\n",
            "        12.0       1.00      0.00      0.00         7\n",
            "        13.0       1.00      0.00      0.00         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       1.00      0.00      0.00         3\n",
            "        22.0       0.67      0.22      0.33         9\n",
            "        23.0       1.00      0.00      0.00         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.00      0.00        11\n",
            "        26.0       1.00      0.00      0.00         3\n",
            "        27.0       1.00      1.00      1.00        10\n",
            "        28.0       1.00      0.20      0.33         5\n",
            "        29.0       1.00      0.00      0.00         4\n",
            "        30.0       1.00      0.43      0.60         7\n",
            "        31.0       0.48      0.92      0.63        63\n",
            "        32.0       1.00      0.38      0.55         8\n",
            "        33.0       0.55      1.00      0.71        12\n",
            "        34.0       1.00      0.00      0.00         3\n",
            "        35.0       1.00      0.00      0.00         6\n",
            "        36.0       1.00      0.00      0.00         6\n",
            "        37.0       1.00      0.00      0.00         2\n",
            "        38.0       1.00      0.00      0.00         8\n",
            "        39.0       0.94      0.44      0.60        39\n",
            "        40.0       1.00      0.38      0.56        13\n",
            "        42.0       0.35      1.00      0.52        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.00      0.00         5\n",
            "        45.0       0.78      0.74      0.76        43\n",
            "        46.0       1.00      0.00      0.00         1\n",
            "        48.0       1.00      0.00      0.00        14\n",
            "        49.0       0.69      0.47      0.56        19\n",
            "        51.0       1.00      0.00      0.00         3\n",
            "        52.0       1.00      0.00      0.00         3\n",
            "        55.0       1.00      0.00      0.00         2\n",
            "        56.0       0.78      0.76      0.77        41\n",
            "        58.0       1.00      0.00      0.00         2\n",
            "        59.0       0.76      0.70      0.73        27\n",
            "        60.0       1.00      0.00      0.00         1\n",
            "        61.0       1.00      0.56      0.71         9\n",
            "        62.0       1.00      0.00      0.00         3\n",
            "        63.0       1.00      0.00      0.00         2\n",
            "        64.0       1.00      0.00      0.00        17\n",
            "        65.0       0.91      0.53      0.67        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.00      0.00         3\n",
            "        68.0       1.00      0.00      0.00        21\n",
            "        69.0       1.00      0.00      0.00         2\n",
            "        70.0       0.80      0.44      0.57         9\n",
            "        71.0       1.00      0.00      0.00         8\n",
            "        72.0       1.00      0.09      0.17        11\n",
            "        73.0       1.00      0.00      0.00         4\n",
            "        74.0       0.86      0.90      0.88        41\n",
            "        75.0       1.00      0.00      0.00         3\n",
            "        76.0       1.00      0.00      0.00         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       1.00      0.00      0.00        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      0.00      0.00         2\n",
            "        81.0       1.00      0.25      0.40         8\n",
            "        82.0       1.00      0.00      0.00         3\n",
            "        83.0       1.00      0.00      0.00         8\n",
            "        84.0       0.39      0.98      0.56        41\n",
            "        86.0       1.00      0.00      0.00         5\n",
            "        87.0       1.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       1.00      0.00      0.00         3\n",
            "        90.0       0.88      0.64      0.74        11\n",
            "        92.0       1.00      0.00      0.00         1\n",
            "        93.0       1.00      0.00      0.00         9\n",
            "        94.0       1.00      0.00      0.00         1\n",
            "        95.0       1.00      0.00      0.00         6\n",
            "        96.0       1.00      0.00      0.00         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      0.00      0.00         5\n",
            "       100.0       1.00      0.00      0.00         2\n",
            "       102.0       1.00      0.00      0.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       0.80      0.27      0.40        15\n",
            "       105.0       1.00      0.00      0.00         4\n",
            "       106.0       1.00      0.14      0.25         7\n",
            "       107.0       1.00      0.00      0.00         2\n",
            "       108.0       1.00      0.00      0.00         2\n",
            "       109.0       1.00      0.00      0.00         4\n",
            "       110.0       1.00      0.00      0.00         5\n",
            "       111.0       1.00      0.00      0.00         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.55      0.67      0.60         9\n",
            "       115.0       1.00      0.00      0.00         3\n",
            "       117.0       1.00      0.00      0.00         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      0.00      0.00         1\n",
            "       120.0       0.67      0.14      0.24        14\n",
            "       121.0       1.00      0.00      0.00         8\n",
            "       122.0       1.00      0.00      0.00         1\n",
            "       123.0       1.00      0.00      0.00        11\n",
            "       124.0       1.00      0.38      0.55         8\n",
            "       125.0       1.00      0.00      0.00         2\n",
            "       126.0       1.00      0.00      0.00         8\n",
            "       127.0       1.00      0.00      0.00         2\n",
            "       128.0       1.00      0.00      0.00        19\n",
            "       129.0       1.00      0.00      0.00         1\n",
            "       130.0       1.00      0.12      0.22         8\n",
            "       131.0       1.00      0.00      0.00         3\n",
            "       132.0       1.00      0.00      0.00         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.00      0.00         3\n",
            "       136.0       1.00      0.00      0.00         4\n",
            "       137.0       1.00      0.00      0.00         3\n",
            "       138.0       1.00      0.00      0.00         9\n",
            "       139.0       1.00      0.00      0.00         4\n",
            "       140.0       1.00      0.00      0.00         5\n",
            "       141.0       1.00      0.00      0.00         1\n",
            "       142.0       1.00      0.00      0.00         1\n",
            "       144.0       1.00      0.21      0.35        14\n",
            "       145.0       0.92      0.85      0.88        13\n",
            "       146.0       1.00      0.00      0.00         4\n",
            "       148.0       1.00      0.00      0.00         3\n",
            "       149.0       1.00      0.00      0.00         3\n",
            "       150.0       1.00      0.00      0.00         1\n",
            "       151.0       1.00      0.00      0.00         2\n",
            "       152.0       0.89      1.00      0.94        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       1.00      0.71      0.83         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       1.00      0.00      0.00        12\n",
            "       158.0       0.57      1.00      0.73        40\n",
            "       160.0       1.00      0.00      0.00         1\n",
            "       161.0       1.00      0.00      0.00         5\n",
            "       162.0       1.00      0.00      0.00         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       1.00      0.11      0.20         9\n",
            "       165.0       1.00      0.00      0.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       1.00      0.00      0.00         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       1.00      0.00      0.00         6\n",
            "       171.0       1.00      0.00      0.00         1\n",
            "       172.0       1.00      0.00      0.00         1\n",
            "       173.0       1.00      0.00      0.00         1\n",
            "       174.0       1.00      0.00      0.00         2\n",
            "       175.0       1.00      0.11      0.20         9\n",
            "       177.0       1.00      0.00      0.00         2\n",
            "       178.0       1.00      0.00      0.00         2\n",
            "       180.0       0.15      1.00      0.25        73\n",
            "       181.0       1.00      0.00      0.00         7\n",
            "       182.0       1.00      0.00      0.00         4\n",
            "       183.0       0.35      0.79      0.49        38\n",
            "       184.0       1.00      0.00      0.00         2\n",
            "       185.0       1.00      0.20      0.33         5\n",
            "       186.0       1.00      0.00      0.00         2\n",
            "       187.0       1.00      0.00      0.00        13\n",
            "       188.0       1.00      0.00      0.00         5\n",
            "       189.0       1.00      0.00      0.00         1\n",
            "       190.0       1.00      0.00      0.00         3\n",
            "       191.0       1.00      0.00      0.00         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.79      0.86      0.82        35\n",
            "       194.0       0.40      0.74      0.52        19\n",
            "       196.0       1.00      0.00      0.00         1\n",
            "       197.0       1.00      0.00      0.00         9\n",
            "       198.0       0.95      0.58      0.72        31\n",
            "       199.0       1.00      0.00      0.00         6\n",
            "       203.0       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.45      1458\n",
            "   macro avg       0.95      0.15      0.15      1458\n",
            "weighted avg       0.81      0.45      0.38      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_names = text_clf.predict(test_data.name)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted_names, zero_division = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrWbC1qVYb5y",
        "outputId": "8b376511-ab20-4520-c30d-1262b89133bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       1.00      0.73      0.85        15\n",
            "         3.0       1.00      0.50      0.67         6\n",
            "         5.0       1.00      0.00      0.00         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.90      0.69      0.78        13\n",
            "         8.0       1.00      0.00      0.00         5\n",
            "         9.0       1.00      0.00      0.00         5\n",
            "        10.0       1.00      0.00      0.00         7\n",
            "        11.0       1.00      0.00      0.00         3\n",
            "        12.0       1.00      0.00      0.00         7\n",
            "        13.0       1.00      0.00      0.00         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       1.00      0.00      0.00         3\n",
            "        22.0       0.67      0.22      0.33         9\n",
            "        23.0       1.00      0.00      0.00         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.00      0.00        11\n",
            "        26.0       1.00      0.00      0.00         3\n",
            "        27.0       1.00      1.00      1.00        10\n",
            "        28.0       1.00      0.20      0.33         5\n",
            "        29.0       1.00      0.00      0.00         4\n",
            "        30.0       1.00      0.43      0.60         7\n",
            "        31.0       0.48      0.92      0.63        63\n",
            "        32.0       1.00      0.38      0.55         8\n",
            "        33.0       0.55      1.00      0.71        12\n",
            "        34.0       1.00      0.00      0.00         3\n",
            "        35.0       1.00      0.00      0.00         6\n",
            "        36.0       1.00      0.00      0.00         6\n",
            "        37.0       1.00      0.00      0.00         2\n",
            "        38.0       1.00      0.00      0.00         8\n",
            "        39.0       0.94      0.44      0.60        39\n",
            "        40.0       1.00      0.38      0.56        13\n",
            "        42.0       0.35      1.00      0.52        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.00      0.00         5\n",
            "        45.0       0.78      0.74      0.76        43\n",
            "        46.0       1.00      0.00      0.00         1\n",
            "        48.0       1.00      0.00      0.00        14\n",
            "        49.0       0.69      0.47      0.56        19\n",
            "        51.0       1.00      0.00      0.00         3\n",
            "        52.0       1.00      0.00      0.00         3\n",
            "        55.0       1.00      0.00      0.00         2\n",
            "        56.0       0.78      0.76      0.77        41\n",
            "        58.0       1.00      0.00      0.00         2\n",
            "        59.0       0.76      0.70      0.73        27\n",
            "        60.0       1.00      0.00      0.00         1\n",
            "        61.0       1.00      0.56      0.71         9\n",
            "        62.0       1.00      0.00      0.00         3\n",
            "        63.0       1.00      0.00      0.00         2\n",
            "        64.0       1.00      0.00      0.00        17\n",
            "        65.0       0.91      0.53      0.67        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.00      0.00         3\n",
            "        68.0       1.00      0.00      0.00        21\n",
            "        69.0       1.00      0.00      0.00         2\n",
            "        70.0       0.80      0.44      0.57         9\n",
            "        71.0       1.00      0.00      0.00         8\n",
            "        72.0       1.00      0.09      0.17        11\n",
            "        73.0       1.00      0.00      0.00         4\n",
            "        74.0       0.86      0.90      0.88        41\n",
            "        75.0       1.00      0.00      0.00         3\n",
            "        76.0       1.00      0.00      0.00         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       1.00      0.00      0.00        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      0.00      0.00         2\n",
            "        81.0       1.00      0.25      0.40         8\n",
            "        82.0       1.00      0.00      0.00         3\n",
            "        83.0       1.00      0.00      0.00         8\n",
            "        84.0       0.39      0.98      0.56        41\n",
            "        86.0       1.00      0.00      0.00         5\n",
            "        87.0       1.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       1.00      0.00      0.00         3\n",
            "        90.0       0.88      0.64      0.74        11\n",
            "        92.0       1.00      0.00      0.00         1\n",
            "        93.0       1.00      0.00      0.00         9\n",
            "        94.0       1.00      0.00      0.00         1\n",
            "        95.0       1.00      0.00      0.00         6\n",
            "        96.0       1.00      0.00      0.00         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      0.00      0.00         5\n",
            "       100.0       1.00      0.00      0.00         2\n",
            "       102.0       1.00      0.00      0.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       0.80      0.27      0.40        15\n",
            "       105.0       1.00      0.00      0.00         4\n",
            "       106.0       1.00      0.14      0.25         7\n",
            "       107.0       1.00      0.00      0.00         2\n",
            "       108.0       1.00      0.00      0.00         2\n",
            "       109.0       1.00      0.00      0.00         4\n",
            "       110.0       1.00      0.00      0.00         5\n",
            "       111.0       1.00      0.00      0.00         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.55      0.67      0.60         9\n",
            "       115.0       1.00      0.00      0.00         3\n",
            "       117.0       1.00      0.00      0.00         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      0.00      0.00         1\n",
            "       120.0       0.67      0.14      0.24        14\n",
            "       121.0       1.00      0.00      0.00         8\n",
            "       122.0       1.00      0.00      0.00         1\n",
            "       123.0       1.00      0.00      0.00        11\n",
            "       124.0       1.00      0.38      0.55         8\n",
            "       125.0       1.00      0.00      0.00         2\n",
            "       126.0       1.00      0.00      0.00         8\n",
            "       127.0       1.00      0.00      0.00         2\n",
            "       128.0       1.00      0.00      0.00        19\n",
            "       129.0       1.00      0.00      0.00         1\n",
            "       130.0       1.00      0.12      0.22         8\n",
            "       131.0       1.00      0.00      0.00         3\n",
            "       132.0       1.00      0.00      0.00         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.00      0.00         3\n",
            "       136.0       1.00      0.00      0.00         4\n",
            "       137.0       1.00      0.00      0.00         3\n",
            "       138.0       1.00      0.00      0.00         9\n",
            "       139.0       1.00      0.00      0.00         4\n",
            "       140.0       1.00      0.00      0.00         5\n",
            "       141.0       1.00      0.00      0.00         1\n",
            "       142.0       1.00      0.00      0.00         1\n",
            "       144.0       1.00      0.21      0.35        14\n",
            "       145.0       0.92      0.85      0.88        13\n",
            "       146.0       1.00      0.00      0.00         4\n",
            "       148.0       1.00      0.00      0.00         3\n",
            "       149.0       1.00      0.00      0.00         3\n",
            "       150.0       1.00      0.00      0.00         1\n",
            "       151.0       1.00      0.00      0.00         2\n",
            "       152.0       0.89      1.00      0.94        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       1.00      0.71      0.83         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       1.00      0.00      0.00        12\n",
            "       158.0       0.57      1.00      0.73        40\n",
            "       160.0       1.00      0.00      0.00         1\n",
            "       161.0       1.00      0.00      0.00         5\n",
            "       162.0       1.00      0.00      0.00         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       1.00      0.11      0.20         9\n",
            "       165.0       1.00      0.00      0.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       1.00      0.00      0.00         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       1.00      0.00      0.00         6\n",
            "       171.0       1.00      0.00      0.00         1\n",
            "       172.0       1.00      0.00      0.00         1\n",
            "       173.0       1.00      0.00      0.00         1\n",
            "       174.0       1.00      0.00      0.00         2\n",
            "       175.0       1.00      0.11      0.20         9\n",
            "       177.0       1.00      0.00      0.00         2\n",
            "       178.0       1.00      0.00      0.00         2\n",
            "       180.0       0.15      1.00      0.25        73\n",
            "       181.0       1.00      0.00      0.00         7\n",
            "       182.0       1.00      0.00      0.00         4\n",
            "       183.0       0.35      0.79      0.49        38\n",
            "       184.0       1.00      0.00      0.00         2\n",
            "       185.0       1.00      0.20      0.33         5\n",
            "       186.0       1.00      0.00      0.00         2\n",
            "       187.0       1.00      0.00      0.00        13\n",
            "       188.0       1.00      0.00      0.00         5\n",
            "       189.0       1.00      0.00      0.00         1\n",
            "       190.0       1.00      0.00      0.00         3\n",
            "       191.0       1.00      0.00      0.00         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.79      0.86      0.82        35\n",
            "       194.0       0.40      0.74      0.52        19\n",
            "       196.0       1.00      0.00      0.00         1\n",
            "       197.0       1.00      0.00      0.00         9\n",
            "       198.0       0.95      0.58      0.72        31\n",
            "       199.0       1.00      0.00      0.00         6\n",
            "       203.0       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.45      1458\n",
            "   macro avg       0.95      0.15      0.15      1458\n",
            "weighted avg       0.81      0.45      0.38      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump"
      ],
      "metadata": {
        "id": "748-mu3KYkSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump(text_clf, 'classification_model1.joblib') \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZmJ-Gm_cDkO",
        "outputId": "b407ce96-33fd-44e5-8b6d-07993c234af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['classification_model1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('classification_model1.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NGYs0YCmcUCF",
        "outputId": "0b6a020b-fc7e-486f-fde1-8de25e5e44bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ff94169a-8751-45ac-a7fd-486af49fddc0\", \"classification_model1.joblib\", 73623714)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dump(encoder, 'category_encoder1.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBRd3pzgcX-x",
        "outputId": "61fd1429-a087-4a3f-a774-233db1bd009d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['category_encoder1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('category_encoder1.joblib')\n"
      ],
      "metadata": {
        "id": "EqG1-SJnhjev",
        "outputId": "32c93e3c-36dc-451c-e327-9441ede22b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dacdd34f-c547-4f0f-948f-3cd4de0bb1dc\", \"category_encoder1.joblib\", 4892)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "])"
      ],
      "metadata": {
        "id": "y1eFL8G6hmLA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(train_data.combined.to_numpy(), Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "GxcdmCPKCoyq",
        "outputId": "0d904d1b-c0e0-4bf3-cb4b-83bbb6ac8f77"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf',\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
              "                               tol=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.001, max_iter=5, random_state=42, tol=None)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.predict([\"wine\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHb_YHOjEBAd",
        "outputId": "bc3ac607-9be8-4368-fb04-7f4e130f577b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([194.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_names = text_clf.predict(test_data.combined)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted_names, zero_division = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gezHCK1SEu6Q",
        "outputId": "e3e8c996-0f69-4f13-f32f-d433a69ad61d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       0.94      1.00      0.97        15\n",
            "         3.0       0.71      0.83      0.77         6\n",
            "         5.0       1.00      0.00      0.00         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.80      0.92      0.86        13\n",
            "         8.0       0.33      0.20      0.25         5\n",
            "         9.0       0.67      0.40      0.50         5\n",
            "        10.0       1.00      0.00      0.00         7\n",
            "        11.0       1.00      1.00      1.00         3\n",
            "        12.0       0.50      0.14      0.22         7\n",
            "        13.0       1.00      1.00      1.00         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       0.67      0.67      0.67         3\n",
            "        22.0       0.75      1.00      0.86         9\n",
            "        23.0       1.00      1.00      1.00         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.09      0.17        11\n",
            "        26.0       0.50      1.00      0.67         3\n",
            "        27.0       0.91      1.00      0.95        10\n",
            "        28.0       0.67      0.80      0.73         5\n",
            "        29.0       0.00      0.00      0.00         4\n",
            "        30.0       1.00      1.00      1.00         7\n",
            "        31.0       0.55      0.83      0.66        63\n",
            "        32.0       1.00      0.88      0.93         8\n",
            "        33.0       0.67      1.00      0.80        12\n",
            "        34.0       1.00      0.67      0.80         3\n",
            "        35.0       0.80      0.67      0.73         6\n",
            "        36.0       1.00      0.00      0.00         6\n",
            "        37.0       1.00      1.00      1.00         2\n",
            "        38.0       0.80      0.50      0.62         8\n",
            "        39.0       0.83      1.00      0.91        39\n",
            "        40.0       0.92      0.92      0.92        13\n",
            "        42.0       0.75      0.98      0.85        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.20      0.33         5\n",
            "        45.0       0.70      0.74      0.72        43\n",
            "        46.0       1.00      1.00      1.00         1\n",
            "        48.0       0.75      0.43      0.55        14\n",
            "        49.0       0.57      0.68      0.62        19\n",
            "        50.0       0.00      1.00      0.00         0\n",
            "        51.0       1.00      0.67      0.80         3\n",
            "        52.0       0.75      1.00      0.86         3\n",
            "        55.0       1.00      0.00      0.00         2\n",
            "        56.0       0.82      0.80      0.81        41\n",
            "        58.0       1.00      1.00      1.00         2\n",
            "        59.0       0.77      0.63      0.69        27\n",
            "        60.0       0.50      1.00      0.67         1\n",
            "        61.0       0.90      1.00      0.95         9\n",
            "        62.0       0.50      0.33      0.40         3\n",
            "        63.0       0.00      0.00      0.00         2\n",
            "        64.0       0.50      0.47      0.48        17\n",
            "        65.0       0.85      0.89      0.87        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.67      0.80         3\n",
            "        68.0       1.00      0.81      0.89        21\n",
            "        69.0       0.67      1.00      0.80         2\n",
            "        70.0       0.64      1.00      0.78         9\n",
            "        71.0       1.00      1.00      1.00         8\n",
            "        72.0       0.91      0.91      0.91        11\n",
            "        73.0       1.00      0.25      0.40         4\n",
            "        74.0       0.91      0.95      0.93        41\n",
            "        75.0       1.00      0.67      0.80         3\n",
            "        76.0       1.00      0.67      0.80         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       0.91      1.00      0.95        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      1.00      1.00         2\n",
            "        81.0       1.00      0.88      0.93         8\n",
            "        82.0       0.67      0.67      0.67         3\n",
            "        83.0       0.62      0.62      0.62         8\n",
            "        84.0       0.57      1.00      0.73        41\n",
            "        86.0       1.00      1.00      1.00         5\n",
            "        87.0       1.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       1.00      0.67      0.80         3\n",
            "        90.0       0.73      0.73      0.73        11\n",
            "        92.0       1.00      1.00      1.00         1\n",
            "        93.0       0.50      0.22      0.31         9\n",
            "        94.0       0.50      1.00      0.67         1\n",
            "        95.0       1.00      0.67      0.80         6\n",
            "        96.0       1.00      0.33      0.50         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      1.00      1.00         5\n",
            "       100.0       1.00      1.00      1.00         2\n",
            "       102.0       1.00      1.00      1.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       1.00      0.80      0.89        15\n",
            "       105.0       1.00      0.25      0.40         4\n",
            "       106.0       0.50      0.29      0.36         7\n",
            "       107.0       1.00      0.50      0.67         2\n",
            "       108.0       1.00      1.00      1.00         2\n",
            "       109.0       0.60      0.75      0.67         4\n",
            "       110.0       0.83      1.00      0.91         5\n",
            "       111.0       1.00      0.62      0.77         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.64      0.78      0.70         9\n",
            "       115.0       1.00      0.33      0.50         3\n",
            "       117.0       0.83      0.56      0.67         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      1.00      1.00         1\n",
            "       120.0       0.70      1.00      0.82        14\n",
            "       121.0       1.00      0.50      0.67         8\n",
            "       122.0       1.00      1.00      1.00         1\n",
            "       123.0       0.71      0.91      0.80        11\n",
            "       124.0       1.00      1.00      1.00         8\n",
            "       125.0       0.67      1.00      0.80         2\n",
            "       126.0       0.50      0.25      0.33         8\n",
            "       127.0       1.00      0.50      0.67         2\n",
            "       128.0       1.00      0.21      0.35        19\n",
            "       129.0       1.00      0.00      0.00         1\n",
            "       130.0       1.00      0.75      0.86         8\n",
            "       131.0       1.00      0.67      0.80         3\n",
            "       132.0       1.00      0.00      0.00         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.67      0.80         3\n",
            "       136.0       1.00      0.25      0.40         4\n",
            "       137.0       1.00      1.00      1.00         3\n",
            "       138.0       0.89      0.89      0.89         9\n",
            "       139.0       0.75      0.75      0.75         4\n",
            "       140.0       0.80      0.80      0.80         5\n",
            "       141.0       0.50      1.00      0.67         1\n",
            "       142.0       0.50      1.00      0.67         1\n",
            "       144.0       0.77      0.71      0.74        14\n",
            "       145.0       0.81      1.00      0.90        13\n",
            "       146.0       1.00      1.00      1.00         4\n",
            "       148.0       1.00      0.67      0.80         3\n",
            "       149.0       1.00      1.00      1.00         3\n",
            "       150.0       1.00      1.00      1.00         1\n",
            "       151.0       1.00      0.50      0.67         2\n",
            "       152.0       0.83      1.00      0.91        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       0.70      1.00      0.82         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       0.50      0.25      0.33        12\n",
            "       158.0       0.74      0.97      0.84        40\n",
            "       160.0       1.00      1.00      1.00         1\n",
            "       161.0       1.00      0.00      0.00         5\n",
            "       162.0       1.00      0.62      0.77         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       0.80      0.89      0.84         9\n",
            "       165.0       1.00      1.00      1.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       0.71      0.62      0.67         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       0.86      1.00      0.92         6\n",
            "       171.0       1.00      0.00      0.00         1\n",
            "       172.0       1.00      1.00      1.00         1\n",
            "       173.0       0.00      0.00      0.00         1\n",
            "       174.0       1.00      1.00      1.00         2\n",
            "       175.0       0.75      1.00      0.86         9\n",
            "       177.0       1.00      0.50      0.67         2\n",
            "       178.0       1.00      1.00      1.00         2\n",
            "       180.0       0.73      0.97      0.84        73\n",
            "       181.0       0.75      0.43      0.55         7\n",
            "       182.0       1.00      1.00      1.00         4\n",
            "       183.0       0.58      0.84      0.69        38\n",
            "       184.0       0.40      1.00      0.57         2\n",
            "       185.0       1.00      1.00      1.00         5\n",
            "       186.0       1.00      0.50      0.67         2\n",
            "       187.0       0.81      1.00      0.90        13\n",
            "       188.0       1.00      0.80      0.89         5\n",
            "       189.0       1.00      0.00      0.00         1\n",
            "       190.0       0.33      0.33      0.33         3\n",
            "       191.0       0.50      1.00      0.67         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.85      1.00      0.92        35\n",
            "       194.0       0.72      0.68      0.70        19\n",
            "       196.0       0.50      1.00      0.67         1\n",
            "       197.0       0.64      0.78      0.70         9\n",
            "       198.0       0.84      0.84      0.84        31\n",
            "       199.0       1.00      0.50      0.67         6\n",
            "       203.0       0.86      0.92      0.89        13\n",
            "\n",
            "    accuracy                           0.76      1458\n",
            "   macro avg       0.84      0.62      0.61      1458\n",
            "weighted avg       0.79      0.76      0.72      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_names = text_clf.predict(test_data.name)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted_names, zero_division = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tysPp_ooE0lb",
        "outputId": "5ad2b67b-641c-4a14-8ccb-628bc52e78b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       0.94      1.00      0.97        15\n",
            "         3.0       0.83      0.83      0.83         6\n",
            "         5.0       1.00      0.17      0.29         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.80      0.92      0.86        13\n",
            "         8.0       0.50      0.40      0.44         5\n",
            "         9.0       0.50      0.20      0.29         5\n",
            "        10.0       0.00      0.00      0.00         7\n",
            "        11.0       1.00      1.00      1.00         3\n",
            "        12.0       1.00      0.29      0.44         7\n",
            "        13.0       0.50      1.00      0.67         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       0.67      0.67      0.67         3\n",
            "        22.0       0.50      0.78      0.61         9\n",
            "        23.0       1.00      0.67      0.80         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.18      0.31        11\n",
            "        26.0       0.50      1.00      0.67         3\n",
            "        27.0       0.71      1.00      0.83        10\n",
            "        28.0       0.83      1.00      0.91         5\n",
            "        29.0       1.00      0.00      0.00         4\n",
            "        30.0       1.00      1.00      1.00         7\n",
            "        31.0       0.46      0.92      0.62        63\n",
            "        32.0       1.00      0.88      0.93         8\n",
            "        33.0       0.53      0.83      0.65        12\n",
            "        34.0       0.67      0.67      0.67         3\n",
            "        35.0       1.00      0.17      0.29         6\n",
            "        36.0       0.00      0.00      0.00         6\n",
            "        37.0       1.00      0.50      0.67         2\n",
            "        38.0       0.80      0.50      0.62         8\n",
            "        39.0       0.75      0.69      0.72        39\n",
            "        40.0       1.00      0.85      0.92        13\n",
            "        42.0       0.82      1.00      0.90        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.20      0.33         5\n",
            "        45.0       0.68      0.65      0.67        43\n",
            "        46.0       1.00      1.00      1.00         1\n",
            "        48.0       0.83      0.36      0.50        14\n",
            "        49.0       0.58      0.74      0.65        19\n",
            "        51.0       1.00      1.00      1.00         3\n",
            "        52.0       0.75      1.00      0.86         3\n",
            "        55.0       0.00      0.00      0.00         2\n",
            "        56.0       0.78      0.76      0.77        41\n",
            "        58.0       1.00      1.00      1.00         2\n",
            "        59.0       0.66      0.78      0.71        27\n",
            "        60.0       0.00      0.00      0.00         1\n",
            "        61.0       0.75      1.00      0.86         9\n",
            "        62.0       0.00      0.00      0.00         3\n",
            "        63.0       0.00      0.00      0.00         2\n",
            "        64.0       0.00      0.00      0.00        17\n",
            "        65.0       0.89      0.84      0.86        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.67      0.80         3\n",
            "        68.0       0.92      0.57      0.71        21\n",
            "        69.0       0.67      1.00      0.80         2\n",
            "        70.0       0.64      1.00      0.78         9\n",
            "        71.0       1.00      1.00      1.00         8\n",
            "        72.0       0.53      0.82      0.64        11\n",
            "        73.0       1.00      0.00      0.00         4\n",
            "        74.0       0.84      0.88      0.86        41\n",
            "        75.0       1.00      0.33      0.50         3\n",
            "        76.0       1.00      0.67      0.80         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       0.90      0.90      0.90        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      0.50      0.67         2\n",
            "        81.0       0.67      0.75      0.71         8\n",
            "        82.0       1.00      0.00      0.00         3\n",
            "        83.0       0.33      0.25      0.29         8\n",
            "        84.0       0.58      0.95      0.72        41\n",
            "        86.0       1.00      1.00      1.00         5\n",
            "        87.0       1.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       0.50      0.33      0.40         3\n",
            "        90.0       0.57      0.73      0.64        11\n",
            "        92.0       1.00      1.00      1.00         1\n",
            "        93.0       0.33      0.11      0.17         9\n",
            "        94.0       0.50      1.00      0.67         1\n",
            "        95.0       1.00      0.00      0.00         6\n",
            "        96.0       0.50      0.33      0.40         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      1.00      1.00         5\n",
            "       100.0       1.00      1.00      1.00         2\n",
            "       102.0       1.00      1.00      1.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       0.59      0.67      0.62        15\n",
            "       105.0       1.00      0.25      0.40         4\n",
            "       106.0       0.33      0.29      0.31         7\n",
            "       107.0       0.33      0.50      0.40         2\n",
            "       108.0       1.00      0.50      0.67         2\n",
            "       109.0       0.67      1.00      0.80         4\n",
            "       110.0       0.83      1.00      0.91         5\n",
            "       111.0       1.00      0.75      0.86         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.50      0.78      0.61         9\n",
            "       115.0       1.00      0.67      0.80         3\n",
            "       117.0       0.86      0.67      0.75         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      0.00      0.00         1\n",
            "       120.0       0.48      0.93      0.63        14\n",
            "       121.0       1.00      0.12      0.22         8\n",
            "       122.0       1.00      0.00      0.00         1\n",
            "       123.0       0.75      0.82      0.78        11\n",
            "       124.0       0.62      1.00      0.76         8\n",
            "       125.0       0.67      1.00      0.80         2\n",
            "       126.0       0.67      0.25      0.36         8\n",
            "       127.0       1.00      1.00      1.00         2\n",
            "       128.0       1.00      0.11      0.19        19\n",
            "       129.0       0.50      1.00      0.67         1\n",
            "       130.0       1.00      0.50      0.67         8\n",
            "       131.0       0.40      0.67      0.50         3\n",
            "       132.0       1.00      0.00      0.00         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.67      0.80         3\n",
            "       136.0       0.00      0.00      0.00         4\n",
            "       137.0       1.00      1.00      1.00         3\n",
            "       138.0       1.00      0.89      0.94         9\n",
            "       139.0       1.00      0.75      0.86         4\n",
            "       140.0       0.60      0.60      0.60         5\n",
            "       141.0       1.00      0.00      0.00         1\n",
            "       142.0       1.00      1.00      1.00         1\n",
            "       144.0       0.65      0.79      0.71        14\n",
            "       145.0       0.87      1.00      0.93        13\n",
            "       146.0       1.00      0.75      0.86         4\n",
            "       147.0       0.00      1.00      0.00         0\n",
            "       148.0       0.00      0.00      0.00         3\n",
            "       149.0       1.00      1.00      1.00         3\n",
            "       150.0       0.50      1.00      0.67         1\n",
            "       151.0       1.00      0.00      0.00         2\n",
            "       152.0       0.83      1.00      0.91        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       0.70      1.00      0.82         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       0.33      0.08      0.13        12\n",
            "       158.0       0.75      0.95      0.84        40\n",
            "       160.0       0.50      1.00      0.67         1\n",
            "       161.0       1.00      0.00      0.00         5\n",
            "       162.0       0.83      0.62      0.71         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       0.73      0.89      0.80         9\n",
            "       165.0       1.00      0.00      0.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       0.75      0.75      0.75         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       0.75      1.00      0.86         6\n",
            "       171.0       0.00      0.00      0.00         1\n",
            "       172.0       0.00      0.00      0.00         1\n",
            "       173.0       0.50      1.00      0.67         1\n",
            "       174.0       1.00      1.00      1.00         2\n",
            "       175.0       0.67      0.89      0.76         9\n",
            "       177.0       1.00      0.00      0.00         2\n",
            "       178.0       1.00      1.00      1.00         2\n",
            "       179.0       0.00      1.00      0.00         0\n",
            "       180.0       0.80      0.92      0.85        73\n",
            "       181.0       1.00      0.43      0.60         7\n",
            "       182.0       0.67      1.00      0.80         4\n",
            "       183.0       0.67      0.79      0.72        38\n",
            "       184.0       0.33      1.00      0.50         2\n",
            "       185.0       0.71      1.00      0.83         5\n",
            "       186.0       1.00      0.00      0.00         2\n",
            "       187.0       0.87      1.00      0.93        13\n",
            "       188.0       1.00      0.60      0.75         5\n",
            "       189.0       0.33      1.00      0.50         1\n",
            "       190.0       0.40      0.67      0.50         3\n",
            "       191.0       0.50      1.00      0.67         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.87      0.94      0.90        35\n",
            "       194.0       0.67      0.74      0.70        19\n",
            "       196.0       1.00      0.00      0.00         1\n",
            "       197.0       0.57      0.44      0.50         9\n",
            "       198.0       0.80      0.77      0.79        31\n",
            "       199.0       1.00      0.67      0.80         6\n",
            "       203.0       0.63      0.92      0.75        13\n",
            "\n",
            "    accuracy                           0.70      1458\n",
            "   macro avg       0.76      0.55      0.51      1458\n",
            "weighted avg       0.74      0.70      0.66      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_names = text_clf.predict(test_data.description)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(target, predicted_names, zero_division = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MvK_Ao1FEQ7",
        "outputId": "49bea167-4d07-4d5c-9851-a4ecc47e578e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.00      0.00         4\n",
            "         1.0       0.70      0.93      0.80        15\n",
            "         3.0       0.71      0.83      0.77         6\n",
            "         5.0       1.00      0.00      0.00         6\n",
            "         6.0       1.00      0.00      0.00         9\n",
            "         7.0       0.64      0.69      0.67        13\n",
            "         8.0       0.25      0.20      0.22         5\n",
            "         9.0       1.00      0.20      0.33         5\n",
            "        10.0       1.00      0.00      0.00         7\n",
            "        11.0       1.00      1.00      1.00         3\n",
            "        12.0       0.33      0.14      0.20         7\n",
            "        13.0       1.00      0.00      0.00         3\n",
            "        15.0       1.00      0.00      0.00         2\n",
            "        19.0       1.00      0.00      0.00         2\n",
            "        21.0       0.50      0.33      0.40         3\n",
            "        22.0       0.64      1.00      0.78         9\n",
            "        23.0       1.00      0.67      0.80         6\n",
            "        24.0       1.00      0.00      0.00         1\n",
            "        25.0       1.00      0.09      0.17        11\n",
            "        26.0       0.50      1.00      0.67         3\n",
            "        27.0       0.90      0.90      0.90        10\n",
            "        28.0       0.50      0.80      0.62         5\n",
            "        29.0       0.00      0.00      0.00         4\n",
            "        30.0       0.88      1.00      0.93         7\n",
            "        31.0       0.28      0.70      0.40        63\n",
            "        32.0       1.00      0.62      0.77         8\n",
            "        33.0       0.69      0.92      0.79        12\n",
            "        34.0       0.50      0.33      0.40         3\n",
            "        35.0       0.80      0.67      0.73         6\n",
            "        36.0       1.00      0.17      0.29         6\n",
            "        37.0       1.00      1.00      1.00         2\n",
            "        38.0       0.75      0.38      0.50         8\n",
            "        39.0       0.87      0.87      0.87        39\n",
            "        40.0       0.90      0.69      0.78        13\n",
            "        42.0       0.76      0.76      0.76        41\n",
            "        43.0       1.00      0.00      0.00         2\n",
            "        44.0       1.00      0.00      0.00         5\n",
            "        45.0       0.64      0.70      0.67        43\n",
            "        46.0       1.00      1.00      1.00         1\n",
            "        48.0       0.80      0.29      0.42        14\n",
            "        49.0       0.62      0.68      0.65        19\n",
            "        51.0       1.00      0.67      0.80         3\n",
            "        52.0       0.75      1.00      0.86         3\n",
            "        55.0       1.00      0.00      0.00         2\n",
            "        56.0       0.76      0.61      0.68        41\n",
            "        58.0       1.00      0.50      0.67         2\n",
            "        59.0       0.56      0.33      0.42        27\n",
            "        60.0       1.00      1.00      1.00         1\n",
            "        61.0       0.90      1.00      0.95         9\n",
            "        62.0       1.00      0.67      0.80         3\n",
            "        63.0       0.00      0.00      0.00         2\n",
            "        64.0       0.43      0.53      0.47        17\n",
            "        65.0       0.70      0.84      0.76        19\n",
            "        66.0       1.00      0.00      0.00         1\n",
            "        67.0       1.00      0.00      0.00         3\n",
            "        68.0       0.93      0.62      0.74        21\n",
            "        69.0       1.00      0.50      0.67         2\n",
            "        70.0       0.50      0.44      0.47         9\n",
            "        71.0       1.00      0.88      0.93         8\n",
            "        72.0       0.82      0.82      0.82        11\n",
            "        73.0       1.00      0.25      0.40         4\n",
            "        74.0       0.79      0.90      0.84        41\n",
            "        75.0       1.00      0.67      0.80         3\n",
            "        76.0       1.00      0.67      0.80         3\n",
            "        77.0       1.00      0.00      0.00         3\n",
            "        78.0       0.83      1.00      0.91        10\n",
            "        79.0       1.00      0.00      0.00         3\n",
            "        80.0       1.00      1.00      1.00         2\n",
            "        81.0       1.00      0.75      0.86         8\n",
            "        82.0       0.67      0.67      0.67         3\n",
            "        83.0       0.71      0.62      0.67         8\n",
            "        84.0       0.55      0.98      0.70        41\n",
            "        86.0       1.00      0.80      0.89         5\n",
            "        87.0       0.00      0.00      0.00         2\n",
            "        88.0       1.00      0.00      0.00         4\n",
            "        89.0       1.00      0.67      0.80         3\n",
            "        90.0       0.62      0.73      0.67        11\n",
            "        92.0       1.00      1.00      1.00         1\n",
            "        93.0       0.67      0.22      0.33         9\n",
            "        94.0       0.50      1.00      0.67         1\n",
            "        95.0       1.00      0.50      0.67         6\n",
            "        96.0       1.00      0.00      0.00         3\n",
            "        98.0       1.00      0.00      0.00         2\n",
            "        99.0       1.00      1.00      1.00         5\n",
            "       100.0       0.50      0.50      0.50         2\n",
            "       102.0       1.00      1.00      1.00         3\n",
            "       103.0       1.00      0.00      0.00         1\n",
            "       104.0       0.83      0.67      0.74        15\n",
            "       105.0       1.00      0.25      0.40         4\n",
            "       106.0       0.60      0.43      0.50         7\n",
            "       107.0       1.00      0.00      0.00         2\n",
            "       108.0       1.00      1.00      1.00         2\n",
            "       109.0       1.00      0.75      0.86         4\n",
            "       110.0       1.00      1.00      1.00         5\n",
            "       111.0       1.00      0.50      0.67         8\n",
            "       112.0       1.00      0.00      0.00         4\n",
            "       113.0       0.70      0.78      0.74         9\n",
            "       115.0       1.00      0.00      0.00         3\n",
            "       117.0       0.75      0.33      0.46         9\n",
            "       118.0       1.00      0.00      0.00         1\n",
            "       119.0       1.00      1.00      1.00         1\n",
            "       120.0       0.61      0.79      0.69        14\n",
            "       121.0       1.00      0.38      0.55         8\n",
            "       122.0       1.00      0.00      0.00         1\n",
            "       123.0       0.73      0.73      0.73        11\n",
            "       124.0       0.89      1.00      0.94         8\n",
            "       125.0       0.50      0.50      0.50         2\n",
            "       126.0       0.00      0.00      0.00         8\n",
            "       127.0       1.00      0.00      0.00         2\n",
            "       128.0       0.86      0.32      0.46        19\n",
            "       129.0       1.00      0.00      0.00         1\n",
            "       130.0       1.00      0.75      0.86         8\n",
            "       131.0       1.00      0.67      0.80         3\n",
            "       132.0       1.00      0.25      0.40         4\n",
            "       133.0       1.00      0.00      0.00         1\n",
            "       134.0       1.00      0.00      0.00         2\n",
            "       135.0       1.00      0.33      0.50         3\n",
            "       136.0       1.00      0.25      0.40         4\n",
            "       137.0       1.00      1.00      1.00         3\n",
            "       138.0       0.80      0.89      0.84         9\n",
            "       139.0       0.67      0.50      0.57         4\n",
            "       140.0       0.67      0.40      0.50         5\n",
            "       141.0       0.50      1.00      0.67         1\n",
            "       142.0       0.50      1.00      0.67         1\n",
            "       144.0       0.67      0.43      0.52        14\n",
            "       145.0       0.76      1.00      0.87        13\n",
            "       146.0       1.00      0.75      0.86         4\n",
            "       148.0       1.00      0.67      0.80         3\n",
            "       149.0       1.00      1.00      1.00         3\n",
            "       150.0       1.00      0.00      0.00         1\n",
            "       151.0       1.00      0.50      0.67         2\n",
            "       152.0       0.76      1.00      0.86        25\n",
            "       153.0       1.00      0.00      0.00         3\n",
            "       154.0       0.60      0.43      0.50         7\n",
            "       155.0       1.00      0.00      0.00         2\n",
            "       156.0       1.00      0.00      0.00         1\n",
            "       157.0       0.62      0.42      0.50        12\n",
            "       158.0       0.69      0.95      0.80        40\n",
            "       160.0       0.50      1.00      0.67         1\n",
            "       161.0       0.00      0.00      0.00         5\n",
            "       162.0       0.67      0.25      0.36         8\n",
            "       163.0       1.00      0.00      0.00         2\n",
            "       164.0       0.73      0.89      0.80         9\n",
            "       165.0       1.00      1.00      1.00         1\n",
            "       166.0       1.00      0.00      0.00         1\n",
            "       167.0       0.60      0.38      0.46         8\n",
            "       169.0       1.00      0.00      0.00         1\n",
            "       170.0       0.86      1.00      0.92         6\n",
            "       171.0       1.00      0.00      0.00         1\n",
            "       172.0       1.00      1.00      1.00         1\n",
            "       173.0       0.00      0.00      0.00         1\n",
            "       174.0       1.00      0.50      0.67         2\n",
            "       175.0       0.90      1.00      0.95         9\n",
            "       177.0       1.00      0.50      0.67         2\n",
            "       178.0       1.00      0.50      0.67         2\n",
            "       179.0       0.00      1.00      0.00         0\n",
            "       180.0       0.68      0.99      0.80        73\n",
            "       181.0       0.50      0.29      0.36         7\n",
            "       182.0       1.00      0.75      0.86         4\n",
            "       183.0       0.52      0.79      0.62        38\n",
            "       184.0       0.50      1.00      0.67         2\n",
            "       185.0       1.00      0.60      0.75         5\n",
            "       186.0       1.00      0.50      0.67         2\n",
            "       187.0       0.87      1.00      0.93        13\n",
            "       188.0       1.00      0.80      0.89         5\n",
            "       189.0       1.00      0.00      0.00         1\n",
            "       190.0       1.00      0.33      0.50         3\n",
            "       191.0       0.50      1.00      0.67         2\n",
            "       192.0       1.00      0.00      0.00         1\n",
            "       193.0       0.69      0.94      0.80        35\n",
            "       194.0       0.80      0.63      0.71        19\n",
            "       196.0       0.50      1.00      0.67         1\n",
            "       197.0       0.55      0.67      0.60         9\n",
            "       198.0       0.76      0.84      0.80        31\n",
            "       199.0       0.75      0.50      0.60         6\n",
            "       203.0       0.79      0.85      0.81        13\n",
            "\n",
            "    accuracy                           0.67      1458\n",
            "   macro avg       0.81      0.52      0.52      1458\n",
            "weighted avg       0.73      0.67      0.64      1458\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSHvCBajFG1q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}